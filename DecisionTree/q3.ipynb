{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "6WZDPwfbhIdN",
    "outputId": "288552bf-2794-4c69-a457-026671d5ba46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cf1l9pcthcwW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import operator\n",
    "import collections\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score,precision_score,f1_score\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6Aa-YQahlMM"
   },
   "source": [
    "# Reading dataset :  1000 x 81  \n",
    "- Columns having NULL values > 70% serve no purpose.\n",
    "There are 4 such columns which are dropped alog with the first column named 'Id'.  \n",
    "- Replacing NA values in numerical data with the mean & in that of categorical data with the mode.  \n",
    "\n",
    "# Node Decision\n",
    "- For deciding which attribute needs to become the node at each level, we are calculating the **MSE** of the columns of dataset and choosing the minimum val and the corresponding attribute for our decision.\n",
    "- MSE calculation involves taking the unique values of the column.\n",
    "- If the column is categorical, then each unique value is considered for node value and mse calcualtion\n",
    "- If numerical, we take mean of adjacent unique values for mse calculation.\n",
    "\n",
    "# Splitting Decision\n",
    "\n",
    "- Based on the node value selected, the split decision needs to be taken.\n",
    "- For numerical attribute, rows whose values are <= node value are considered for left subtree creation and remaining for right subtree.\n",
    "- For categorical attribute, rows whose values are == node value are considered for left subtreeand remaining for right subtree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kePPeHZhKbJk"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "  def __init__(self,at,val):\n",
    "    self.left=None\n",
    "    self.right=None\n",
    "    self.attribute=at\n",
    "    self.value=val\n",
    "    # self.leaf=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_22YUhC9hepP"
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "  def __init_(self):\n",
    "    self.columnx=[-1]\n",
    "\n",
    "\n",
    "  def train(self,path):\n",
    "    self.columnx=[-1]\n",
    "    self.dataset=pd.read_csv(path)\n",
    "    # print(dataset)\n",
    "    self.dataset=self.dataset.drop(self.dataset.columns[0],axis=1)\n",
    "    # print(dt)\n",
    "    # print(self.dataset.nunique())\n",
    "    self.dataset['MSZoning']=self.dataset['MSZoning'].replace('C (all)','C')\n",
    "    self.dataset['MasVnrType']=self.dataset['MasVnrType'].replace('None',np.nan)\n",
    "    # print(dataset[dataset.columns[1]])\n",
    "    nullvaluecount=self.dataset.isnull().sum(axis=0)\n",
    "    # print(type(nullvaluecount))\n",
    "    self.dropcolumn=[]\n",
    "    for i in range(len(nullvaluecount)):\n",
    "      if(nullvaluecount[i]/1000>=0.7):\n",
    "        self.dropcolumn.append(i)\n",
    "    self.dataset=self.dataset.drop(self.dataset.columns[self.dropcolumn],axis=1)\n",
    "    # print(dataset)\n",
    "    # print('Mean')\n",
    "    self.dataset.fillna(self.dataset.mean(),inplace=True)\n",
    "    # print(dataset)\n",
    "    nullvaluecount=self.dataset.isnull().sum(axis=0)\n",
    "    # print(nullvaluecount)\n",
    "    self.dataset.fillna(self.dataset.mode().iloc[0],inplace=True)\n",
    "    # self.datanumpy=self.dataset.to_numpy()\n",
    "    # print('Mode')\n",
    "    # print(self.dataset)\n",
    "  \n",
    "  def mse(self,list1,list2):\n",
    "    total_size=len(list1)+len(list2)\n",
    "    mean_of_list1=np.mean(list1)\n",
    "    mean_of_list2=np.mean(list2)\n",
    "    list1=list1-mean_of_list1\n",
    "    list2=list2-mean_of_list2\n",
    "    list1=np.square(list1)\n",
    "    list2=np.square(list2)\n",
    "    mse_of_list1=np.sum(list1)*len(list1)/total_size\n",
    "    mse_of_list2=np.sum(list2)*len(list2)/total_size\n",
    "    return mse_of_list1+mse_of_list2\n",
    "\n",
    "  def split(self,dataset):\n",
    "    minmse=math.inf\n",
    "    attribute_selected=0\n",
    "    splitvalue=0\n",
    "    # print('split function---')\n",
    "    for i in range(np.size(dataset,1)-1):\n",
    "      if(i not in self.columnx):\n",
    "        unique_entries=np.unique(dataset[:,i])\n",
    "        # print(unique_entries)\n",
    "        # unique_entry_type=type(unique_entries[0])\n",
    "        # print(unique_entry_type)\n",
    "        if(isinstance(unique_entries[0],int) or isinstance(unique_entries[0],float)):\n",
    "          mean_of_adjacent_unique_entries=[]\n",
    "          for x in range(len(unique_entries)-1):\n",
    "            mean_of_adjacent_unique_entries.append((unique_entries[x]+unique_entries[x+1])/2)\n",
    "          # print(mean_of_adjacent_unique_entries)\n",
    "          for item in mean_of_adjacent_unique_entries:\n",
    "            list1=[]\n",
    "            list2=[]\n",
    "            for j in range(len(dataset[:,i])):\n",
    "              # print(dataset[j][i])\n",
    "              if(dataset[j][i]<=item):\n",
    "                list1.append(dataset[j][-1])\n",
    "              else:\n",
    "                list2.append(dataset[j][-1])\n",
    "            # print(len(list1))\n",
    "            # print(len(list2))\n",
    "            value_from_mse=self.mse(list1,list2)\n",
    "            if(value_from_mse<minmse):\n",
    "              minmse=value_from_mse\n",
    "              attribute_selected=i\n",
    "              splitvalue=item\n",
    "          # print(minmse,attribute_selected,splitvalue)\n",
    "\n",
    "        else:\n",
    "          # print('str')\n",
    "          # minmse=math.inf\n",
    "          # attribute_selected=0\n",
    "          # splitvalue=''\n",
    "          for item in unique_entries:\n",
    "            list1=[]\n",
    "            list2=[]\n",
    "            l1=[]\n",
    "            l2=[]\n",
    "            # print(item)\n",
    "            for j in range(len(dataset[:,i])):\n",
    "              if(dataset[j][i]==item):\n",
    "                # l1.append(dataset[j][i])\n",
    "                list1.append(dataset[j][-1])\n",
    "              else:\n",
    "                # l2.append(dataset[j][i])\n",
    "                list2.append(dataset[j][-1])\n",
    "            value_from_mse=self.mse(list1,list2)\n",
    "            # print(value_from_mse)\n",
    "            if(value_from_mse<minmse):\n",
    "              minmse=value_from_mse\n",
    "              attribute_selected=i\n",
    "              splitvalue=item\n",
    "            # print(list1)\n",
    "            # print('---')\n",
    "            # print(list2)\n",
    "          # print(minmse,attribute_selected,splitvalue)\n",
    "    self.columnx.append(attribute_selected)\n",
    "    return minmse,attribute_selected,splitvalue\n",
    "    # print(dataset[0,attribute_selected])\n",
    "\n",
    "  def bintree(self,dataset):\n",
    "    # if(np.size(dataset,0)==0):\n",
    "    #   return None\n",
    "    if(np.size(dataset,0)<=40):\n",
    "      # print(dataset[:,-1])\n",
    "      # print(\"size : \",np.size(dataset,0))\n",
    "      val=np.mean(dataset[:,-1],axis=0)\n",
    "      root=Node(-1,val)\n",
    "      # root.leaf=True\n",
    "      return root\n",
    "    else:\n",
    "      leftdataset=[]\n",
    "      rightdataset=[]\n",
    "      rightdataset=[]\n",
    "      mse,column_idx,value=self.split(dataset)\n",
    "      # print(mse,column_idx,value)\n",
    "      root=Node(column_idx,value)\n",
    "      #Split dataset into 2 subsections for left & right subtrees\n",
    "      # print(type(value))\n",
    "      if(isinstance(value,str)):\n",
    "        for j in range(len(dataset[:,0])):\n",
    "          if(dataset[j][column_idx]==value):\n",
    "            # leftdataset=np.vstack([leftdataset,dataset[j,:]])\n",
    "            leftdataset.append(dataset[j,:])\n",
    "          else:\n",
    "            # rightdataset=np.vstack([rightdataset,dataset[j,:]])\n",
    "            rightdataset.append(dataset[j,:])\n",
    "      else:\n",
    "        for j in range(len(dataset[:,0])):\n",
    "          if(dataset[j][column_idx]<=value):\n",
    "            # leftdataset=np.vstack([leftdataset,dataset[j,:]])\n",
    "            leftdataset.append(dataset[j,:])\n",
    "          else:\n",
    "            # rightdataset=np.vstack([rightdataset,dataset[j,:]])\n",
    "            rightdataset.append(dataset[j,:])\n",
    "\n",
    "      # print(np.size(leftdataset,0))\n",
    "      # print(np.size(rightdataset,0))\n",
    "      # print(rightdataset)\n",
    "      if(np.size(leftdataset,0)==0):\n",
    "        root.left=None\n",
    "        newn=Node(-1,np.mean(np.array(rightdataset)[:,-1],axis=0))\n",
    "        root.right=newn\n",
    "        return root\n",
    "      elif(np.size(rightdataset,0)==0):\n",
    "        root.right=None\n",
    "        newn=Node(-1,np.mean(np.array(leftdataset)[:,-1],axis=0))\n",
    "        root.left=newn\n",
    "      else:\n",
    "        root.left=self.bintree(np.array(leftdataset))\n",
    "        root.right=self.bintree(np.array(rightdataset))\n",
    "      return root\n",
    "\n",
    "  def inorder(self,root):\n",
    "    if(root==None):\n",
    "      return None\n",
    "    self.inorder(root.left)\n",
    "    print(root.val)\n",
    "    self.inorder(root.right)\n",
    "\n",
    "  def predictvalue(self,row,root):\n",
    "    # print(root.attribute)\n",
    "    # print(root.value)\n",
    "    # print('----')\n",
    "    if(root.attribute==-1):\n",
    "      return root.value\n",
    "    # print(row[root.attribute])\n",
    "    if(isinstance(row[root.attribute],str)):\n",
    "      if(row[root.attribute]==root.value):\n",
    "        return self.predictvalue(row,root.left)\n",
    "      else:\n",
    "        return self.predictvalue(row,root.right)\n",
    "\n",
    "    else:\n",
    "      if(row[root.attribute]<=root.value):\n",
    "        return self.predictvalue(row,root.left)\n",
    "      else:\n",
    "        return self.predictvalue(row,root.right)\n",
    "\n",
    "\n",
    "  def predict(self,filename,root):\n",
    "    pv=[]\n",
    "    testdata=pd.read_csv(filename)\n",
    "    testdata=testdata.drop(testdata.columns[0],axis=1)\n",
    "    testdata=testdata.drop(testdata.columns[self.dropcolumn],axis=1)\n",
    "    testdata['MSZoning']=testdata['MSZoning'].replace('C (all)','C')\n",
    "    testdata['MasVnrType']=testdata['MasVnrType'].replace('None',np.nan)\n",
    "    testdata.fillna(testdata.mean(),inplace=True)\n",
    "    testdata.fillna(testdata.mode().iloc[0],inplace=True)\n",
    "    self.testdf=testdata\n",
    "    testdata.to_numpy()\n",
    "    # print(row)\n",
    "    # row=testdata.iloc[427,:]\n",
    "    for i in range(np.size(testdata,0)):\n",
    "      # print(\"i\",i)\n",
    "\n",
    "      row=testdata.iloc[i,:]\n",
    "      pv.append(self.predictvalue(row,root))\n",
    "    return pv\n",
    "\n",
    "  def sklearn_decisiontree(self,testlabel):\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    regr_1 = DecisionTreeRegressor(max_depth=2)\n",
    "    regr_2 = DecisionTreeRegressor(max_depth=5)\n",
    "    for col in self.dataset.columns:\n",
    "      if(self.dataset[col].dtype=='object'):\n",
    "        self.dataset[col]=label_encoder.fit_transform(self.dataset[col])\n",
    "        self.testdf[col]=label_encoder.fit_transform(self.testdf[col])\n",
    "    datanp=self.dataset.to_numpy()\n",
    "    testnp=self.testdf.to_numpy()\n",
    "    regr_1.fit(datanp[:,:-1], datanp[:,-1])\n",
    "    regr_2.fit(datanp[:,:-1], datanp[:,-1])\n",
    "    y_1 = regr_1.predict(testnp)\n",
    "    y_2 = regr_2.predict(testnp)\n",
    "    print('Sklearn Decision Tree Regressor')\n",
    "    print('R2 score for depth 2 :',r2_score(testlabel,y_1))\n",
    "    print('R2 score for depth 5 :',r2_score(testlabel,y_2))\n",
    "    print('MSE (2): ',mean_squared_error(testlabel,y_1))\n",
    "    print('MSE (5): ',mean_squared_error(testlabel,y_2))\n",
    "\n",
    "  def mean_always(self,testlabel):\n",
    "    print('Mean always approach')\n",
    "    nparray=self.dataset.to_numpy()\n",
    "    predicted_values=[]\n",
    "    prices=nparray[:,-1]\n",
    "    meanvalue=np.mean(prices)\n",
    "    testnp=self.testdf.to_numpy()\n",
    "    for i in range(np.size(testnp,0)):\n",
    "      predicted_values.append(meanvalue)\n",
    "    print('R2 Score:',r2_score(testlabel,predicted_values))\n",
    "    print('MSE : ',mean_squared_error(testlabel,predicted_values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wtITHo_O6-g"
   },
   "source": [
    "Checking for count of null values in each column of the dataset and unique values in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "FmWg-u5g2_lr",
    "outputId": "0c322b9e-baae-4021-bdfa-c5a77c5f629d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score :  0.6455370975250683\n",
      "MSE :  1873267331.1057253\n",
      "MAE :  28608.74709904811\n",
      "Sklearn Decision Tree Regressor\n",
      "R2 score for depth 2 : 0.5822160270362079\n",
      "R2 score for depth 5 : 0.7106811223528589\n",
      "MSE (2):  2207906843.1370697\n",
      "MSE (5):  1528993860.8085887\n",
      "Mean always approach\n",
      "R2 Score: -0.007125647313121597\n",
      "MSE :  5322462690.052036\n"
     ]
    }
   ],
   "source": [
    "dt=DecisionTree()\n",
    "filename='./Datasets/q3/train.csv'\n",
    "dt.train(filename)\n",
    "# print(dt.dataset)\n",
    "datanumpy=dt.dataset.to_numpy()\n",
    "# print(datanumpy[8,:])\n",
    "# dt.split(datanumpy)\n",
    "root=dt.bintree(datanumpy)\n",
    "predictlabels=dt.predict('./Datasets/q3/test.csv',root)\n",
    "testlabel=pd.read_csv('./Datasets/q3/test_labels.csv',header=None)\n",
    "testlabel=testlabel.drop(testlabel.columns[0],axis=1)\n",
    "print('R2 score : ',r2_score(testlabel.to_numpy(),predictlabels))\n",
    "print('MSE : ',mean_squared_error(testlabel.to_numpy(),predictlabels))\n",
    "print('MAE : ',mean_absolute_error(testlabel.to_numpy(),predictlabels))\n",
    "dt.sklearn_decisiontree(testlabel.to_numpy())\n",
    "dt.mean_always(testlabel.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "20zXbEBihGTK"
   },
   "source": [
    "# Observation\n",
    "## Scratch decision tree\n",
    "\n",
    "> As *leaf dataset count* increases r2 score increases, MSE decreases.\n",
    "\n",
    "## Sklearn Decision tree\n",
    ">As *depth* of tree increases, the MSE decreases.\n",
    "\n",
    "## Mean Always approach\n",
    "> Strict No! r2 score is negative i.e. worse than horizontal line  \n",
    "> High MSE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "soDaUMdjiEam"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "q3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
